# DSPy Provider Configuration
# Options: ollama, claude, openai, gemini
DSPY_PROVIDER=ollama

# Ollama Configuration
OLLAMA_MODEL=gemma3:27b
OLLAMA_BASE_URL=http://localhost:11434

# Claude Configuration (if using DSPY_PROVIDER=claude)
# ANTHROPIC_API_KEY=your-claude-api-key-here

# OpenAI Configuration (if using DSPY_PROVIDER=openai)
# OPENAI_API_KEY=your-openai-api-key-here

# Gemini Configuration (if using DSPY_PROVIDER=gemini)
# GOOGLE_API_KEY=your-gemini-api-key-here

# LLM Generation Settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1024

# Debug Mode - Shows DSPy prompts and LLM responses
DSPY_DEBUG=false

# Agent Loop Configuration
AGENT_MAX_ITERATIONS=5
AGENT_TIMEOUT_SECONDS=60.0