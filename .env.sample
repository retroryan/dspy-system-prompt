# ============================================
# LLM CONFIGURATION
# ============================================
# Direct model specification (provider/model format)
# Examples:
#   - openai/gpt-4o-mini
#   - anthropic/claude-3-opus-20240229  
#   - gemini/gemini-1.5-pro
#   - cohere/command-r-plus
#   - replicate/meta/llama-2-70b-chat
#   - openrouter/google/palm-2-chat-bison
#   - openrouter/anthropic/claude-3-opus
#   - openrouter/meta-llama/llama-3-70b-instruct
#
# Ollama models (use ollama_chat/ prefix for chat models):
#   - ollama_chat/gemma3:27b                # High-quality reasoning
#   - ollama_chat/llama3.2:latest          # Latest Llama 3.2
#   - ollama_chat/llama3.1:8b              # Llama 3.1 8B
#   - ollama_chat/deepseek-r1:14b          # DeepSeek R1 14B
#   - ollama_chat/deepseek-r1:8b           # DeepSeek R1 8B (smaller)
#   - ollama_chat/qwen3:8b                 # Qwen 3 8B
#   - ollama_chat/mistral:7b               # Mistral 7B
#   - ollama_chat/llama3.2:1b              # Llama 3.2 1B (lightweight)
#   - ollama_chat/llama3.3:latest          # Latest Llama 3.3
#   - ollama_chat/phi3:latest              # Microsoft Phi-3
#   - ollama_chat/codellama:latest         # Code-specialized model
#   - ollama_chat/dolphin-mistral:latest   # Uncensored Mistral variant
LLM_MODEL=openai/gpt-4o-mini

# LLM Generation Settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1024
LLM_RETRIES=3
LLM_CACHE=true

# For local models (Ollama, vLLM, etc), set API base:
# OLLAMA_CHAT_API_BASE=http://localhost:11434
# Or pass api_base directly in code:
# Example: setup_llm("ollama_chat/llama3.2", api_base="http://localhost:11434")

# ============================================
# API KEYS (required based on provider)
# ============================================
# OpenAI (required for openai/* models)
# OPENAI_API_KEY=your-openai-api-key-here

# Anthropic Claude (required for anthropic/* models)
# ANTHROPIC_API_KEY=your-claude-api-key-here

# Google Gemini (required for gemini/* models)
# GOOGLE_API_KEY=your-gemini-api-key-here

# Cohere (required for cohere/* models)
# COHERE_API_KEY=your-cohere-api-key-here

# Replicate (required for replicate/* models)
# REPLICATE_API_TOKEN=your-replicate-token-here

# OpenRouter (required for openrouter/* models)
# OPENROUTER_API_KEY=your-openrouter-api-key-here
# OPENROUTER_API_BASE=https://openrouter.ai/api/v1  # Optional, this is the default
# OR_SITE_URL=https://yourapp.com  # Optional, for OpenRouter analytics
# OR_APP_NAME=YourAppName  # Optional, for OpenRouter analytics

# ============================================
# DEBUG & MONITORING
# ============================================
# Debug Mode - Shows DSPy prompts and LLM responses
DSPY_DEBUG=false

# Demo Debug Mode - Shows additional demo execution details
DEMO_DEBUG=true

# Agent Loop Configuration
AGENT_MAX_ITERATIONS=10
AGENT_TIMEOUT_SECONDS=60.0